{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Face Detection.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ZZW8b5ycDB9K","colab_type":"text"},"source":["## Face Detection with the Webcam"]},{"cell_type":"markdown","metadata":{"id":"Q4AXYhjA183G","colab_type":"text"},"source":["### Step 1: Mount Google Drive to store captured videos and config files"]},{"cell_type":"code","metadata":{"id":"DMLihG_Cl70Q","colab_type":"code","outputId":"289e6949-302f-4fca-979f-758a0bf2e2f9","executionInfo":{"status":"ok","timestamp":1567530554540,"user_tz":-120,"elapsed":43086,"user":{"displayName":"Offer SADEY","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA5aATjZURgQjLNxWQX50D4uT8pjrukJ9ir045M=s64","userId":"04235682036546471763"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"An44PbJR2Jn8","colab_type":"text"},"source":["### Step 2: Manage the Webcam and prepare video captures"]},{"cell_type":"code","metadata":{"id":"PPU_CQgW2hOG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":842},"outputId":"a30496c5-1e17-4025-d7c2-d0a40f7771ea","executionInfo":{"status":"ok","timestamp":1567530561726,"user_tz":-120,"elapsed":20013,"user":{"displayName":"Offer SADEY","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA5aATjZURgQjLNxWQX50D4uT8pjrukJ9ir045M=s64","userId":"04235682036546471763"}}},"source":["!pip install ffmpeg-python\n","\n","\n","from IPython.display import HTML, Javascript, display\n","from google.colab.output import eval_js\n","from base64 import b64decode\n","import numpy as np\n","import io\n","import ffmpeg\n","\n","video_file_train = '/content/drive/My Drive/Colab Notebooks/Video Datasets/osy_train.mp4' \n","video_file_test = '/content/drive/My Drive/Colab Notebooks/Video Datasets/osy_test.mp4' \n","  \n","\n","VIDEO_HTML = \"\"\"\n","<script>\n","var my_div = document.createElement(\"DIV\");\n","var my_p = document.createElement(\"P\");\n","var my_btn = document.createElement(\"BUTTON\");\n","var my_btn_txt = document.createTextNode(\"Press to start recording\");\n","\n","my_btn.appendChild(my_btn_txt);\n","my_div.appendChild(my_btn);\n","document.body.appendChild(my_div);\n","\n","var base64data = 0;\n","var reader;\n","var recorder, videoStream;\n","var recordButton = my_btn;\n","\n","var handleSuccess = function(stream) {\n","  videoStream = stream;\n","  var options = {  \n","    mimeType : 'video/webm;codecs=vp9'  \n","  };            \n","  recorder = new MediaRecorder(stream, options);\n","  recorder.ondataavailable = function(e) {            \n","    var url = URL.createObjectURL(e.data);\n","    var preview = document.createElement('video');\n","    preview.controls = true;\n","    preview.src = url;\n","    document.body.appendChild(preview);\n","\n","    reader = new FileReader();\n","    reader.readAsDataURL(e.data); \n","    reader.onloadend = function() {\n","      base64data = reader.result;\n","    }\n","  };\n","  recorder.start();\n","  };\n","\n","recordButton.innerText = \"Recording... press to stop\";\n","\n","navigator.mediaDevices.getUserMedia({video: true}).then(handleSuccess);\n","\n","\n","function toggleRecording() {\n","  if (recorder && recorder.state == \"recording\") {\n","      recorder.stop();\n","      videoStream.getVideoTracks()[0].stop();\n","      recordButton.innerText = \"Saving the recording... Please wait!\"\n","  }\n","}\n","\n","function sleep(ms) {\n","  return new Promise(resolve => setTimeout(resolve, ms));\n","}\n","\n","var data = new Promise(resolve=>{\n","recordButton.onclick = ()=>{\n","toggleRecording()\n","\n","sleep(2000).then(() => {\n","  // wait 2000ms for the data to be available\n","  resolve(base64data.toString())\n","\n","});\n","\n","}\n","});\n","      \n","</script>\n","\"\"\"\n","\n","def start_webcam():\n","  js = Javascript('''\n","    async function startWebcam() {\n","      const div = document.createElement('div');\n","\n","      const video = document.createElement('video');\n","      video.style.display = 'block';\n","      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n","\n","      document.body.appendChild(div);\n","      div.appendChild(video);\n","      video.srcObject = stream;\n","      await video.play();\n","\n","      // Resize the output to fit the video element.\n","      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n","      \n","      return;\n","\n","    }\n","    ''')\n","  \n","  display(js)\n","  data = eval_js('startWebcam()')\n","  \n","    \n","start_webcam()\n","\n","def get_video():\n","  display(HTML(VIDEO_HTML))\n","  data = eval_js(\"data\")\n","  binary = b64decode(data.split(',')[1])\n","  \n","  return binary\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting ffmpeg-python\n","  Downloading https://files.pythonhosted.org/packages/d7/0c/56be52741f75bad4dc6555991fabd2e07b432d333da82c11ad701123888a/ffmpeg_python-0.2.0-py3-none-any.whl\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from ffmpeg-python) (0.16.0)\n","Installing collected packages: ffmpeg-python\n","Successfully installed ffmpeg-python-0.2.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/javascript":["\n","    async function startWebcam() {\n","      const div = document.createElement('div');\n","\n","      const video = document.createElement('video');\n","      video.style.display = 'block';\n","      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n","\n","      document.body.appendChild(div);\n","      div.appendChild(video);\n","      video.srcObject = stream;\n","      await video.play();\n","\n","      // Resize the output to fit the video element.\n","      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n","      \n","      return;\n","\n","    }\n","    "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"4dlrW0aV2jLa","colab_type":"text"},"source":["### Step 3: Capture a video that will be used for AI Training"]},{"cell_type":"code","metadata":{"id":"Uat7tjre2mgZ","colab_type":"code","colab":{}},"source":["videofile = get_video()\n","\n","with open(video_file_train, 'wb') as f:\n","  f.write(videofile)\n","  "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9cTXwpRK2qGQ","colab_type":"text"},"source":["### Step 4: Capture a video that will be used for the Face detection"]},{"cell_type":"code","metadata":{"id":"TZHonmHA2vEe","colab_type":"code","colab":{}},"source":["videofile = get_video()\n","\n","with open(video_file_test, 'wb') as f:\n","  f.write(videofile)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ssvh_ZWq88qt","colab_type":"text"},"source":["### Step 5: Extract the first 30 images of the Train Video file and store them into the Dataset folder (PNG images) "]},{"cell_type":"code","metadata":{"id":"deTXItNE9Ga2","colab_type":"code","colab":{}},"source":["import cv2, sys, numpy, os\n","from time import sleep\n","from google.colab.patches import cv2_imshow\n","\n","# OpenCV Default config file for face detection\n","haar_file = '/content/drive/My Drive/Colab Notebooks/Config/haarcascade_frontalface_default.xml'\n","  \n","# Root Folder used to store the face data images\n","datasets = '/content/drive/My Drive/Colab Notebooks/Image Datasets'\n"," \n","# Subfolder used to store my images (to be changed with your name)\n","sub_data = 'Offer'     \n","  \n","path = os.path.join(datasets, sub_data) \n","if not os.path.isdir(path): \n","    os.mkdir(path) \n","  \n","# define the size of images  \n","(width, height) = (130, 100)     \n","  \n","# Analyse the video training file \n","face_cascade = cv2.CascadeClassifier(haar_file) \n","webcam = cv2.VideoCapture(video_file_train)  \n","  \n","# Capture the first 30 images of the train video\n","count = 1\n","while count < 30: \n","    if not webcam.isOpened():\n","        print('Unable to load the video file.')\n","        sleep(5)\n","        pass  \n","    (_, im) = webcam.read() \n","    gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY) \n","    faces = face_cascade.detectMultiScale(gray, 1.3, 4) \n","    for (x, y, w, h) in faces: \n","        cv2.rectangle(im, (x, y), (x + w, y + h), (255, 0, 0), 2) \n","        face = gray[y:y + h, x:x + w] \n","        face_resize = cv2.resize(face, (width, height)) \n","        cv2.imwrite('% s/% s.png' % (path, count), face_resize) \n","    count += 1\n","      \n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QfaOErqB9DBo","colab_type":"text"},"source":["### Step 6: Train the AI with the image dataset then try to recognize faces"]},{"cell_type":"code","metadata":{"id":"u-r0vodG9TYo","colab_type":"code","colab":{}},"source":["# User OpenCV Face Recognizer to train the AI & Cascade Classifier to detect faces\n","  \n","# Create a list of images and a list of corresponding names \n","(images, lables, names, id) = ([], [], {}, 0) \n","for (subdirs, dirs, files) in os.walk(datasets): \n","    for subdir in dirs: \n","        names[id] = subdir \n","        subjectpath = os.path.join(datasets, subdir) \n","        for filename in os.listdir(subjectpath): \n","            path = subjectpath + '/' + filename \n","            lable = id\n","            images.append(cv2.imread(path, 0)) \n","            lables.append(int(lable)) \n","        id += 1\n","(width, height) = (130, 100) \n","  \n","# Create a Numpy array from the two lists above \n","(images, lables) = [numpy.array(lis) for lis in [images, lables]] \n","  \n","# Train the model from the images with OpenCV Face Recognizer\n","model = cv2.face.LBPHFaceRecognizer_create()\n","model.train(images, lables) \n","  \n","# Use OpenCV Cascade Classifier to detect faces \n","face_cascade = cv2.CascadeClassifier(haar_file) \n","webcam = cv2.VideoCapture(video_file_test)\n","\n","count = 1\n","while count < 30:\n","    (_, im) = webcam.read() \n","    gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY) \n","    faces = face_cascade.detectMultiScale(gray, 1.3, 5) \n","    for (x, y, w, h) in faces: \n","        cv2.rectangle(im, (x, y), (x + w, y + h), (255, 0, 0), 2) \n","        face = gray[y:y + h, x:x + w] \n","        face_resize = cv2.resize(face, (width, height)) \n","        # Try to recognize the face \n","        prediction = model.predict(face_resize) \n","        cv2.rectangle(im, (x, y), (x + w, y + h), (0, 255, 0), 3) \n","  \n","        if prediction[1]<100: \n","           cv2.putText(im, '% s - %.0f' % (names[prediction[0]], prediction[1]), (x-10, y-10), cv2.FONT_HERSHEY_PLAIN, 1, (0, 255, 0)) \n","           cv2_imshow(im)\n","           break\n","        else: \n","          cv2.putText(im, 'not recognized', (x-10, y-10), cv2.FONT_HERSHEY_PLAIN, 1, (0, 255, 0)) \n","  \n","    count += 1\n","      \n"],"execution_count":0,"outputs":[]}]}